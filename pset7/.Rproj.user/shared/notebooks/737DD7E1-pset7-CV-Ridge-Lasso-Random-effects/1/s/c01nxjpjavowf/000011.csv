"0","# create a data frame to keep track of the metrics"
"0","metrics = data.frame(fold = 1:k,"
"0","                     llr1se = NA, "
"0","                     llrmin = NA,"
"0","                     lllas1se = NA,"
"0","                     lllasmin = NA,"
"0","                     llm1 = NA,"
"0","                     llm2 = NA)"
"0",""
"0","# initialize the prediction columns"
"0","dm[, c('r.1se', 'las.1se', 'r.min', 'las.min', 'm1pred', 'm2pred')] = NA"
"0",""
"0","# loop through the folds"
"0","for (j in 1:k){"
"0","  cat(j,'')"
"0","  "
"0","  ## train rows are the ones not in the j-th fold"
"0","  train.rows <- dm$fold != j"
"0","  "
"0","  # test rows are the observations in the j-th fold"
"0","  test.rows  <- dm$fold == j"
"0","  "
"0","  ## ======"
"0","  ## fit models to training data"
"0","  ## ======"
"0","  "
"0","  ## logistic regression with no regularization using only NDVI100"
"0","  m1 = glm(veg ~ NDVI100, data = dm[train.rows, 1:10], family = ""binomial"")"
"0",""
"0","  ## logistic regression with no regularization using all band values"
"0","  m2 = glm(veg ~ ., data = dm[train.rows,1:10], family = ""binomial"")"
"0","  "
"0","  ## logistic regression with ridge regularization using all band values"
"0","  r.train <- cv.glmnet(x = x[train.rows,], y = dm$veg[train.rows], family = 'binomial', alpha = 0)"
"0","  "
"0","  ## logistic regression with lasso regularization using all band values"
"0","  las.train <- cv.glmnet(x = x[train.rows,], y = dm$veg[train.rows], family = 'binomial', alpha = 1)"
"0","  "
"0","  ## ======"
"0","  ## make predictions"
"0","  ## ======"
"0","  "
"0","  dm$m1pred[test.rows] = predict(m1, newdata=dm[test.rows,], type='response')"
"0","  dm$m2pred[test.rows] = predict(m2, newdata=dm[test.rows,], type='response')"
"0","  dm$r.1se[test.rows] = predict(r.train, newx=x[test.rows,], s='lambda.1se', type='response')"
"0","  dm$r.min[test.rows] = predict(r.train, newx=x[test.rows,], s='lambda.min', type='response')"
"0","  dm$las.1se[test.rows] = predict(las.train, newx=x[test.rows,], s='lambda.1se', type='response')"
"0","  dm$las.min[test.rows] = predict(las.train, newx=x[test.rows,], s='lambda.min', type='response')"
"0","  "
"0","  ## Test logloss for each fold"
"0","  metrics[j,'llr1se'] = -mean(dm$veg[test.rows]*"
"0","                                  log(dm$r.1se[test.rows]) +"
"0","                                  (1-dm$veg[test.rows])*"
"0","                                  log(1-dm$r.1se[test.rows]))"
"0","  metrics[j,'llrmin'] = -mean(dm$veg[test.rows]*"
"0","                                  log(dm$r.min[test.rows]) +"
"0","                                  (1-dm$veg[test.rows])*"
"0","                                  log(1-dm$r.min[test.rows]))"
"0","  metrics[j,'lllas1se'] = -mean(dm$veg[test.rows]*"
"0","                                  log(dm$las.1se[test.rows]) +"
"0","                                  (1-dm$veg[test.rows])*"
"0","                                  log(1-dm$las.1se[test.rows]))"
"0","  metrics[j,'lllasmin'] = -mean(dm$veg[test.rows]*"
"0","                                  log(dm$las.min[test.rows]) +"
"0","                                  (1-dm$veg[test.rows])*"
"0","                                  log(1-dm$las.min[test.rows]))"
"0","  metrics[j,'llm1'] = -mean(dm$veg[test.rows]*"
"0","                                  log(dm$m1pred[test.rows]) +"
"0","                                  (1-dm$veg[test.rows])*"
"0","                                  log(1-dm$m1pred[test.rows]))"
"0","  metrics[j,'llm2'] = -mean(dm$veg[test.rows]*"
"0","                                  log(dm$m2pred[test.rows]) +"
"0","                                  (1-dm$veg[test.rows])*"
"0","                                  log(1-dm$m2pred[test.rows]))"
"0","  "
"0","}"
"1","1"
"1"," "
"1",""
"1","2"
"1"," "
"1",""
"1","3"
"1"," "
"1",""
"1","4"
"1"," "
"1",""
"2","Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred"
"1","5"
"1"," "
"1",""
